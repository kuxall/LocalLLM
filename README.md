# LocalLLM

Building a Local LLM to run locally, without the need of a server. Takes input as a pdf file and ask the question to the user.